# This workflow will install Python dependencies, run tests and lint with a single version of Python
# For more information see: https://help.github.com/actions/language-and-framework-guides/using-python-with-github-actions

name: PDF Corpus Collection and Annotation

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]


jobs:
# Stage 2. Crawler tests
  collecting-articles-from-internet:
    name: Download PDF articles
    runs-on: ubuntu-latest
    timeout-minutes: 10

    steps:
    - uses: actions/checkout@v2
    - name: Set up Python 3.9
      uses: actions/setup-python@v2
      with:
        python-version: 3.9
    - name: Cache pip
      uses: actions/cache@v2
      with:
        # This path is specific to Ubuntu
        path: ~/.cache/pip
        # Look to see if there is a cache hit for the corresponding requirements file
        key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
          ${{ runner.os }}-
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements_qa.txt
        pip install -r requirements.txt
    - name: Crawl a raw dataset from web
      run: |
        TARGET_SCORE=$(bash config/get_scrapper_target_score.sh)

        if [[ ${TARGET_SCORE} != 0 ]]; then
          bash config/stage_2_crawler_tests/s2_3_collect_articles_from_internet_pdf.sh
          ls -la tmp/articles
        else
          echo "Skipping stage"
        fi
    - name: Archive raw dataset
      uses: actions/upload-artifact@v2
      with:
        name: raw-dataset
        path: |
          tmp/articles
        retention-days: 40

  checking-articles-dataset:
    name: Validate PDF dataset
    needs: [
        collecting-articles-from-internet
    ]
    runs-on: ubuntu-latest
    timeout-minutes: 5

    steps:
    - uses: actions/checkout@v2
    - name: Set up Python 3.9
      uses: actions/setup-python@v2
      with:
        python-version: 3.9
    - name: Cache pip
      uses: actions/cache@v2
      with:
        # This path is specific to Ubuntu
        path: ~/.cache/pip
        # Look to see if there is a cache hit for the corresponding requirements file
        key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
          ${{ runner.os }}-
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements_qa.txt
        pip install -r requirements.txt
    - name: Download previously collected dataset
      continue-on-error: true
      uses: actions/download-artifact@v2
      with:
        name: raw-dataset
    - name: Run metadata validation
      run: |
        echo "Validate raw data"
        TARGET_SCORE=$(bash config/get_scrapper_target_score.sh)

        if [[ ${TARGET_SCORE} != 0 ]]; then
          mkdir -p tmp/articles
          mv *_raw.txt tmp/articles
          if [[ ${TARGET_SCORE} != 4 ]]; then
            mv *_meta.json tmp/articles
          fi
          bash config/stage_2_crawler_tests/s2_4_check_raw_data.sh
        else
          echo "Skipping stage"
        fi

# Stage 3. Pipeline tests
  checking-raw-dataset-before-running-pipeline:
    name: Pipe verifies PDF dataset
    needs: [
        checking-articles-dataset
    ]
    runs-on: ubuntu-latest
    timeout-minutes: 1

    steps:
    - uses: actions/checkout@v2
    - name: Set up Python 3.9
      uses: actions/setup-python@v2
      with:
        python-version: 3.9
    - name: Cache pip
      uses: actions/cache@v2
      with:
        # This path is specific to Ubuntu
        path: ~/.cache/pip
        # Look to see if there is a cache hit for the corresponding requirements file
        key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
          ${{ runner.os }}-
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements_qa.txt
        pip install -r requirements.txt
    - name: Download previously collected dataset
      continue-on-error: true
      uses: actions/download-artifact@v2
      with:
        name: raw-dataset
    - name: Run crawler config checks
      run: |
        TARGET_SCORE=$(bash config/get_pipeline_target_score.sh)

        if [[ ${TARGET_SCORE} != 0 ]]; then
          mkdir -p tmp/articles
          if [[ ${TARGET_SCORE} != 4 ]]; then
            mv *_meta.json tmp/articles
          fi
          mv *_raw.txt tmp/articles
          python -m pytest -m "mark10 and stage_3_1_dataset_sanity_checks"
        else
          echo "Skip stage"
        fi

  checking-corpus-manager-creates-instances-correctly:
    name: CorpusManager detects PDF articles
    needs: [
        checking-raw-dataset-before-running-pipeline
    ]
    runs-on: ubuntu-latest
    timeout-minutes: 2

    steps:
      - uses: actions/checkout@v2
      - name: Set up Python 3.9
        uses: actions/setup-python@v2
        with:
          python-version: 3.9
      - name: Cache pip
        uses: actions/cache@v2
        with:
          # This path is specific to Ubuntu
          path: ~/.cache/pip
          # Look to see if there is a cache hit for the corresponding requirements file
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-
            ${{ runner.os }}-
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements_qa.txt
          pip install -r requirements.txt
      - name: Download previously collected dataset
        continue-on-error: true
        uses: actions/download-artifact@v2
        with:
          name: raw-dataset
      - name: Run CorpusManager tests
        run: |
          TARGET_SCORE=$(bash config/get_pipeline_target_score.sh)

          if [[ ${TARGET_SCORE} != 0 ]]; then
            mkdir -p tmp/articles
            if [[ ${TARGET_SCORE} != 4 ]]; then
              mv *_meta.json tmp/articles
            fi
            mv *_raw.txt tmp/articles
            bash config/stage_3_pipeline_tests/s3_2_corpus_manager.sh
            ls -la tmp/articles
          else
            echo "Skip stage"
          fi

  checking-student-processing-works-for-admin-dataset:
    name: Pipe processed admin PDF data
    needs: [
        checking-raw-dataset-before-running-pipeline
    ]
    runs-on: ubuntu-latest
    timeout-minutes: 5

    steps:
    - uses: actions/checkout@v2
    - name: Set up Python 3.9
      uses: actions/setup-python@v2
      with:
        python-version: 3.9
    - name: Cache pip
      uses: actions/cache@v2
      with:
        # This path is specific to Ubuntu
        path: ~/.cache/pip
        # Look to see if there is a cache hit for the corresponding requirements file
        key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
          ${{ runner.os }}-
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements_qa.txt
        pip install -r requirements.txt
    - name: Download previously collected dataset
      continue-on-error: true
      uses: actions/download-artifact@v2
      with:
        name: raw-dataset
    - name: Run metadata validation
      run: |
        TARGET_SCORE=$(bash config/get_pipeline_target_score.sh)

        if [[ ${TARGET_SCORE} != 0 ]]; then
          mkdir -p tmp/articles
          if [[ ${TARGET_SCORE} != 4 ]]; then
            mv *_meta.json tmp/articles
          fi
          mv *_raw.txt tmp/articles
          bash config/stage_3_pipeline_tests/s3_3_reference_text_preprocess.sh
          ls -la tmp/articles
        else
          echo "Skip stage"
        fi

  run-student-processing:
    name: Pipe processed student PDF data
    needs: [
        checking-raw-dataset-before-running-pipeline
    ]
    runs-on: ubuntu-latest
    timeout-minutes: 5

    steps:
    - uses: actions/checkout@v2
    - name: Set up Python 3.9
      uses: actions/setup-python@v2
      with:
        python-version: 3.9
    - name: Cache pip
      uses: actions/cache@v2
      with:
        # This path is specific to Ubuntu
        path: ~/.cache/pip
        # Look to see if there is a cache hit for the corresponding requirements file
        key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
          ${{ runner.os }}-
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements_qa.txt
        pip install -r requirements.txt
    - name: Download previously collected dataset
      continue-on-error: true
      uses: actions/download-artifact@v2
      with:
        name: raw-dataset
    - name: Run validation of `_processed.txt` files
      run: |
        TARGET_SCORE=$(bash config/get_pipeline_target_score.sh)

        if [[ ${TARGET_SCORE} != 0 ]]; then
          mkdir -p tmp/articles
          if [[ ${TARGET_SCORE} != 4 ]]; then
            mv *_meta.json tmp/articles
          fi
          mv *_raw.txt tmp/articles
          python pipeline.py
          ls -la tmp/articles
        else
          echo "Skip stage"
        fi
    - name: Archive processed dataset
      continue-on-error: true
      uses: actions/upload-artifact@v2
      with:
        name: processed-dataset
        path: |
          tmp/articles
        retention-days: 40

  checking-student-processing-works-for-student-dataset:
    name: Validate final PDF dataset
    needs: [
        run-student-processing
    ]
    runs-on: ubuntu-latest
    timeout-minutes: 5

    steps:
    - uses: actions/checkout@v2
    - name: Set up Python 3.9
      uses: actions/setup-python@v2
      with:
        python-version: 3.9
    - name: Cache pip
      uses: actions/cache@v2
      with:
        # This path is specific to Ubuntu
        path: ~/.cache/pip
        # Look to see if there is a cache hit for the corresponding requirements file
        key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
          ${{ runner.os }}-
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements_qa.txt
        pip install -r requirements.txt
    - name: Download previously collected dataset
      continue-on-error: true
      uses: actions/download-artifact@v2
      with:
        name: processed-dataset
    - name: Run validation of `_processed.txt` files
      run: |
        TARGET_SCORE=$(bash config/get_pipeline_target_score.sh)

        if [[ ${TARGET_SCORE} != 0 ]]; then
          mkdir -p tmp/articles
          mv *_cleaned.txt tmp/articles
          if [[ ${TARGET_SCORE} != 4 ]]; then
            mv *_meta.json tmp/articles
            mv *_single_tagged.txt tmp/articles
            if [[ ${TARGET_SCORE} != 6 ]]; then
              mv *_multiple_tagged.txt tmp/articles
            fi
          fi
          mv *_raw.txt tmp/articles
          bash config/stage_3_pipeline_tests/s3_4_student_text_preprocess.sh
        else
          echo "Skip stage"
        fi
